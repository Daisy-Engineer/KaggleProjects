{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BERT.ipynb","provenance":[],"mount_file_id":"10gmVT-8XsBsfvd_-0oTAC9zMFsXkYLUy","authorship_tag":"ABX9TyNsmDawHF7kP8IOxbzuaSVF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"SHig9Ut3seoW","colab_type":"text"},"source":["This project is to predict whether a question asked on Quora is sincere or not. The data is from https://www.kaggle.com/c/quora-insincere-questions-classification/data. \n","\n","This project is based on the Notebook (https://www.kaggle.com/sergeykalutsky/introducing-bert-with-tensorflow)"]},{"cell_type":"code","metadata":{"id":"sD0sHd9TbkKp","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593279064668,"user_tz":360,"elapsed":753,"user":{"displayName":"Daisy Ning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpI3TemLZxAxEZYyHk6mfRdz3SnlngkEApMWms=s64","userId":"09384674971162553598"}}},"source":["import pandas as pd\n","import os\n","import numpy as np\n","import pandas as pd\n","import zipfile\n","from matplotlib import pyplot as plt\n","%matplotlib inline\n","import sys\n","import datetime"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"fO2VKd3Or92T","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593279067463,"user_tz":360,"elapsed":2012,"user":{"displayName":"Daisy Ning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpI3TemLZxAxEZYyHk6mfRdz3SnlngkEApMWms=s64","userId":"09384674971162553598"}}},"source":["!unzip -uq \"/content/drive/My Drive/Python/BERT/quora-insincere-questions-classification.zip\" -d \"/content/drive/My Drive/Python/BERT\" "],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"b8XK0sNXbnrf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1593279075488,"user_tz":360,"elapsed":5256,"user":{"displayName":"Daisy Ning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpI3TemLZxAxEZYyHk6mfRdz3SnlngkEApMWms=s64","userId":"09384674971162553598"}},"outputId":"a3983247-3317-49f8-ccf2-29575c00c2bf"},"source":["#downloading weights and cofiguration file for the model\n","!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip"],"execution_count":18,"outputs":[{"output_type":"stream","text":["--2020-06-27 17:31:10--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.23.128, 74.125.203.128, 74.125.204.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.23.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 407727028 (389M) [application/zip]\n","Saving to: ‘uncased_L-12_H-768_A-12.zip.1’\n","\n","uncased_L-12_H-768_ 100%[===================>] 388.84M   135MB/s    in 2.9s    \n","\n","2020-06-27 17:31:14 (135 MB/s) - ‘uncased_L-12_H-768_A-12.zip.1’ saved [407727028/407727028]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7aeulMpCjpin","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593279081121,"user_tz":360,"elapsed":4818,"user":{"displayName":"Daisy Ning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpI3TemLZxAxEZYyHk6mfRdz3SnlngkEApMWms=s64","userId":"09384674971162553598"}}},"source":["repo = 'model_repo'\n","with zipfile.ZipFile(\"uncased_L-12_H-768_A-12.zip\",\"r\") as zip_ref:\n","    zip_ref.extractall(repo)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"XhyZc_MzpfdE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593279084270,"user_tz":360,"elapsed":2072,"user":{"displayName":"Daisy Ning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpI3TemLZxAxEZYyHk6mfRdz3SnlngkEApMWms=s64","userId":"09384674971162553598"}},"outputId":"a0c880c3-20b1-47eb-c548-185b251b1571"},"source":["!ls 'model_repo/uncased_L-12_H-768_A-12'"],"execution_count":20,"outputs":[{"output_type":"stream","text":["bert_config.json\t\t     bert_model.ckpt.index  vocab.txt\n","bert_model.ckpt.data-00000-of-00001  bert_model.ckpt.meta\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jmvbhI6mplzw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":765},"executionInfo":{"status":"ok","timestamp":1593279091421,"user_tz":360,"elapsed":6028,"user":{"displayName":"Daisy Ning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpI3TemLZxAxEZYyHk6mfRdz3SnlngkEApMWms=s64","userId":"09384674971162553598"}},"outputId":"514640dc-cf86-4252-b9d5-c2aebf6ba2fa"},"source":["!wget https://raw.githubusercontent.com/google-research/bert/master/modeling.py \n","!wget https://raw.githubusercontent.com/google-research/bert/master/optimization.py \n","!wget https://raw.githubusercontent.com/google-research/bert/master/run_classifier.py \n","!wget https://raw.githubusercontent.com/google-research/bert/master/tokenization.py "],"execution_count":21,"outputs":[{"output_type":"stream","text":["--2020-06-27 17:31:25--  https://raw.githubusercontent.com/google-research/bert/master/modeling.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 37922 (37K) [text/plain]\n","Saving to: ‘modeling.py.1’\n","\n","modeling.py.1       100%[===================>]  37.03K  --.-KB/s    in 0.02s   \n","\n","2020-06-27 17:31:26 (2.35 MB/s) - ‘modeling.py.1’ saved [37922/37922]\n","\n","--2020-06-27 17:31:27--  https://raw.githubusercontent.com/google-research/bert/master/optimization.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 6258 (6.1K) [text/plain]\n","Saving to: ‘optimization.py.1’\n","\n","optimization.py.1   100%[===================>]   6.11K  --.-KB/s    in 0s      \n","\n","2020-06-27 17:31:27 (32.7 MB/s) - ‘optimization.py.1’ saved [6258/6258]\n","\n","--2020-06-27 17:31:28--  https://raw.githubusercontent.com/google-research/bert/master/run_classifier.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 34783 (34K) [text/plain]\n","Saving to: ‘run_classifier.py.1’\n","\n","run_classifier.py.1 100%[===================>]  33.97K  --.-KB/s    in 0.01s   \n","\n","2020-06-27 17:31:29 (2.36 MB/s) - ‘run_classifier.py.1’ saved [34783/34783]\n","\n","--2020-06-27 17:31:29--  https://raw.githubusercontent.com/google-research/bert/master/tokenization.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 12257 (12K) [text/plain]\n","Saving to: ‘tokenization.py.1’\n","\n","tokenization.py.1   100%[===================>]  11.97K  --.-KB/s    in 0s      \n","\n","2020-06-27 17:31:30 (74.1 MB/s) - ‘tokenization.py.1’ saved [12257/12257]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-V-R2gqupoRM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593279093327,"user_tz":360,"elapsed":508,"user":{"displayName":"Daisy Ning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpI3TemLZxAxEZYyHk6mfRdz3SnlngkEApMWms=s64","userId":"09384674971162553598"}},"outputId":"bb7863dc-1b2d-44b3-dac7-6bd190042f5f"},"source":["# Available pretrained model checkpoints:\n","#   uncased_L-12_H-768_A-12: uncased BERT base model\n","#   uncased_L-24_H-1024_A-16: uncased BERT large model\n","#   cased_L-12_H-768_A-12: cased BERT large model\n","# We will use the most basic one\n","BERT_MODEL = 'uncased_L-12_H-768_A-12'\n","BERT_PRETRAINED_DIR = f'{repo}/uncased_L-12_H-768_A-12'\n","OUTPUT_DIR = f'{repo}/outputs'\n","print(f'***** Model output directory: {OUTPUT_DIR} *****')        #f': expression evaluated at run-time\n","print(f'***** BERT pretrained directory: {BERT_PRETRAINED_DIR} *****')"],"execution_count":22,"outputs":[{"output_type":"stream","text":["***** Model output directory: model_repo/outputs *****\n","***** BERT pretrained directory: model_repo/uncased_L-12_H-768_A-12 *****\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hEfFn65Jn35c","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593279095597,"user_tz":360,"elapsed":532,"user":{"displayName":"Daisy Ning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpI3TemLZxAxEZYyHk6mfRdz3SnlngkEApMWms=s64","userId":"09384674971162553598"}}},"source":[""],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"X8y8eNG0pwL_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593279099541,"user_tz":360,"elapsed":3113,"user":{"displayName":"Daisy Ning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpI3TemLZxAxEZYyHk6mfRdz3SnlngkEApMWms=s64","userId":"09384674971162553598"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","train_df =  pd.read_csv('/content/drive/My Drive/Python/BERT/train.csv')\n","train_df = train_df.sample(2000)\n","\n","train, test = train_test_split(train_df, test_size = 0.1, random_state=42)\n","\n","train_lines, train_labels = train.question_text.values, train.target.values\n","test_lines, test_labels = test.question_text.values, test.target.values"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"t_efTvsBqAiN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":435},"executionInfo":{"status":"error","timestamp":1593298611292,"user_tz":360,"elapsed":3909,"user":{"displayName":"Daisy Ning","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhpI3TemLZxAxEZYyHk6mfRdz3SnlngkEApMWms=s64","userId":"09384674971162553598"}},"outputId":"cc41b344-eacb-4aa2-a5ac-7825b18ce872"},"source":["# Prepare and import BERT model\n","import sys\n","\n","!test -d bert_repo || git clone https://github.com/google-research/bert bert_repo\n","if not 'bert_repo' in sys.path:\n","  sys.path += ['bert_repo']\n","\n","# import python modules defined by BERT\n","import modeling\n","import optimization\n","import run_classifier\n","import run_classifier_with_tfhub\n","import tokenization\n","\n","# import tfhub \n","import tensorflow_hub as hub\n","\n","# import modeling\n","# import optimization\n","# import run_classifier\n","# import tokenization\n","# import tensorflow as tf\n","\n","\n","def create_examples(lines, set_type, labels=None):\n","#Generate data for the BERT model\n","    guid = f'{set_type}'\n","    examples = []\n","    if guid == 'train':\n","        for line, label in zip(lines, labels):\n","            text_a = line\n","            label = str(label)\n","            examples.append(\n","              run_classifier.InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n","    else:\n","        for line in lines:\n","            text_a = line\n","            label = '0'\n","            examples.append(\n","              run_classifier.InputExample(guid=guid, text_a=text_a, text_b=None, label=label))\n","    return examples\n","\n","# Initilize Hyper Parameters\n","TRAIN_BATCH_SIZE = 32\n","EVAL_BATCH_SIZE = 8\n","LEARNING_RATE = 2e-5\n","NUM_TRAIN_EPOCHS = 3.0\n","WARMUP_PROPORTION = 0.1\n","MAX_SEQ_LENGTH = 128\n","\n","# Model configs\n","SAVE_CHECKPOINTS_STEPS = 1000 #if you wish to finetune a model on a larger dataset, use larger interval\n","\n","# each checpoint weights about 1,5gb\n","ITERATIONS_PER_LOOP = 1000\n","NUM_TPU_CORES = 8\n","VOCAB_FILE = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n","CONFIG_FILE = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n","INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n","DO_LOWER_CASE = BERT_MODEL.startswith('uncased')\n","\n","label_list = ['0', '1']\n","tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case=DO_LOWER_CASE)\n","train_examples = create_examples(train_lines, 'train', labels=train_labels)\n","\n","# setup TPU related config\n","tpu_cluster_resolver = None #Since training will happen on GPU, we won't need a cluster resolver\n","# If used in TPU, the estimator is: tf.contrib.tpu.EPUEstimator\n","# TPUEstimator also supports training on CPU and GPU. You don't need to define a separate tf.estimator.Estimator.\n","# But if run in GPU, it might be more efficient to do the following changes:\n","#    - change 'tf.contrib.tpu.TPUEstimator' to 'tf.estimator.Estimator'\n","#    - in model_fn, change 'tf.contrib.tpu.TPUEstimatorSpec'to 'tf.estimator.EstimatorSpec'\n","#    - Notes: https://www.jianshu.com/p/aa2eff7ec5c1\n","\n","run_config = tf.contrib.tpu.RunConfig(\n","    cluster=tpu_cluster_resolver,\n","    model_dir=OUTPUT_DIR,\n","    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n","    tpu_config=tf.contrib.tpu.TPUConfig(\n","        iterations_per_loop=ITERATIONS_PER_LOOP,\n","        num_shards=NUM_TPU_CORES,\n","        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n","\n","# compute number of train and warmup steps from batch size\n","num_train_steps = int(len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n","num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n","\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'bert_repo'...\n","remote: Enumerating objects: 340, done.\u001b[K\n","remote: Total 340 (delta 0), reused 0 (delta 0), pack-reused 340\u001b[K\n","Receiving objects: 100% (340/340), 317.20 KiB | 1.83 MiB/s, done.\n","Resolving deltas: 100% (185/185), done.\n"],"name":"stdout"},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-72eac0e71d1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# import python modules defined by BERT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodeling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0moptimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrun_classifier_with_tfhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/bert_repo/optimization.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mAdamWeightDecayOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m   \u001b[0;34m\"\"\"A basic Adam optimizer that includes \"correct\" L2 weight decay.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.train' has no attribute 'Optimizer'"]}]},{"cell_type":"code","metadata":{"id":"C3AbB9H7isrt","colab_type":"code","colab":{}},"source":["# Fine-tune and Run Predictions on a pretrained BERT Model from TF Hub\n","model_fn = run_classifier.model_fn_builder(\n","    bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n","    num_labels=len(label_list),\n","    init_checkpoint=INIT_CHECKPOINT,\n","    learning_rate=LEARNING_RATE,\n","    num_train_steps=num_train_steps,\n","    num_warmup_steps=num_warmup_steps,\n","    use_tpu=False, #If False training will fall on CPU or GPU, depending on what is available  \n","    use_one_hot_embeddings=True)\n","\n","estimator = tf.contrib.tpu.TPUEstimator(\n","    use_tpu=False, #If False training will fall on CPU or GPU, depending on what is available \n","    model_fn=model_fn,\n","    config=run_config,\n","    train_batch_size=TRAIN_BATCH_SIZE,\n","    eval_batch_size=EVAL_BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H-fa2KgyqxlT","colab_type":"code","colab":{}},"source":["\"\"\"\n","Note: You might see a message 'Running train on CPU'. \n","This really just means that it's running on something other than a Cloud TPU, which includes a GPU.\n","\"\"\"\n","\n","# Train the model.\n","print('Please wait...')\n","train_features = run_classifier.convert_examples_to_features(\n","    train_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","print('***** Started training at {} *****'.format(datetime.datetime.now()))\n","print('  Num examples = {}'.format(len(train_examples)))\n","print('  Batch size = {}'.format(TRAIN_BATCH_SIZE))\n","tf.logging.info(\"  Num steps = %d\", num_train_steps)\n","train_input_fn = run_classifier.input_fn_builder(\n","    features=train_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=True,\n","    drop_remainder=True)\n","estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","print('***** Finished training at {} *****'.format(datetime.datetime.now()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IIljBVupqxo8","colab_type":"code","colab":{}},"source":["\"\"\"\n","There is a weird bug in original code.\n","When predicting, estimator returns an empty dict {}, without batch_size.\n","I redefine input_fn_builder and hardcode batch_size, ignoring 'params' for now.\n","\"\"\"\n","\n","def input_fn_builder(features, seq_length, is_training, drop_remainder):\n","  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n","\n","  all_input_ids = []\n","  all_input_mask = []\n","  all_segment_ids = []\n","  all_label_ids = []\n","\n","  for feature in features:\n","    all_input_ids.append(feature.input_ids)\n","    all_input_mask.append(feature.input_mask)\n","    all_segment_ids.append(feature.segment_ids)\n","    all_label_ids.append(feature.label_id)\n","\n","  def input_fn(params):\n","    \"\"\"The actual input function.\"\"\"\n","    print(params)\n","    batch_size = 32\n","    num_examples = len(features)\n","\n","    d = tf.data.Dataset.from_tensor_slices({\n","        \"input_ids\":\n","            tf.constant(\n","                all_input_ids, shape=[num_examples, seq_length],\n","                dtype=tf.int32),\n","        \"input_mask\":\n","            tf.constant(\n","                all_input_mask,\n","                shape=[num_examples, seq_length],\n","                dtype=tf.int32),\n","        \"segment_ids\":\n","            tf.constant(\n","                all_segment_ids,\n","                shape=[num_examples, seq_length],\n","                dtype=tf.int32),\n","        \"label_ids\":\n","            tf.constant(all_label_ids, shape=[num_examples], dtype=tf.int32),\n","    })\n","\n","    if is_training:\n","      d = d.repeat()\n","      d = d.shuffle(buffer_size=100)\n","\n","    d = d.batch(batch_size=batch_size, drop_remainder=drop_remainder)\n","    return d\n","\n","  return input_fn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rtNPwXH-qxxA","colab_type":"code","colab":{}},"source":["predict_examples = create_examples(test_lines, 'test')\n","\n","predict_features = run_classifier.convert_examples_to_features(\n","    predict_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","\n","predict_input_fn = input_fn_builder(\n","    features=predict_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=False,\n","    drop_remainder=False)\n","\n","result = estimator.predict(input_fn=predict_input_fn)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zQORgUrqqx0M","colab_type":"code","colab":{}},"source":["from tqdm import tqdm\n","preds = []\n","for prediction in tqdm(result):\n","    for class_probability in prediction:\n","      preds.append(float(class_probability))\n","\n","results = []\n","for i in tqdm(range(0,len(preds),2)):\n","  if preds[i] < 0.9:\n","    results.append(1)\n","  else:\n","    results.append(0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fb3lg7pfrzQc","colab_type":"code","colab":{}},"source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","\n","print(accuracy_score(np.array(results), test_labels))\n","print(f1_score(np.array(results), test_labels))"],"execution_count":null,"outputs":[]}]}