{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a Kaggle project (https://www.kaggle.com/uciml/breast-cancer-wisconsin-data). The purpose is to predict Breast Cancer based on the features. There are five steps included:\n",
    "1. Understand the problem\n",
    "2. Clean data\n",
    "3. Select feature\n",
    "4. Try different algorithms\n",
    "5. Model prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Understand the problem\n",
    "\n",
    "The data file is a csv file. \n",
    "\n",
    "Rows: How many samples do we have?\n",
    "\n",
    "Columns:\n",
    "- y: Is the breast cancer Malignant or Benign? - Binary classification\n",
    "    - There are 357 benign, 212 malignant - imbalanced, which means KNN might not be a good classifier.\n",
    "    \n",
    "- X: How many features are useful? Are there any relationship among different features? Are they numerical/categorical?\n",
    "    - delete the useless columns, such as 'id'\n",
    "    - 'radius_mean', 'perimeter_mean' and 'area_mean' are related. - If an algorithm requires independent variables, we should delete the redundant features.\n",
    "    - both 'area_mean' and 'area_se' describe 'area', but they refer to different features. Therefore, they should not be treated as redundant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Clean&Analyze the data\n",
    "\n",
    "- Delete the useless columns such as 'id'\n",
    "- There is no NULL in the dataset, which means this dataset is ready to use\n",
    "- Visualize data to see how features affect cancer type (eg: what's the range of radius_mean for Malignant/Benign type?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Select features\n",
    "\n",
    "Five methods are useful to select features (https://scikit-learn.org/stable/modules/feature_selection.html)\n",
    "- Remove features with low variance\n",
    "    - Not good for imbalanced samples (1000 is negative while 10 is positive)\n",
    "       'from sklearn.feature_selection import VarianceThreshold\n",
    "        result=VarianceThreshold(threshold=0.5).fit_transform(data.data)'\n",
    "- correlation map (use 'sns.heatmap') \n",
    "    - This method might be a little subjective.\n",
    "    - This only works for numerical features. (For categorical features, it's difficult to )\n",
    "- SelectKBest, which only keep the most important k features\n",
    "- Recursive feature elimination (RFE) \n",
    "    - RFE with random forest, which deletes the least important features\n",
    "    - RFE with cross-validation & Random Forest. - The optimal # of features will be selected automatically\n",
    "- L1 based feature selection / tree based feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Try different algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is about binary classification, I tried multiple methods:\n",
    "- KNN - good for small datasets\n",
    "- Random Forest - \n",
    "- Logistic regression\n",
    "- SVC - not easy to find good parameters for C & gamma\n",
    "\n",
    "Calculate the accuracy and then select the one with the highest accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Model prediction\n",
    "- This project does not provide new data for prediction. So this step is ignored here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Summary\n",
    "- Feature selection is more important than algorithm selection.\n",
    "    - Different groups of feature will generate very different accuracy scores. However, if we use the same features but different algorithms, the accuracy scores won't change that much.\n",
    "- Since this is a breat cancer identification problem, will it be necessary to decrease the false positive rate besides increasing the accuracy? Yes. Therefore, the algorithm that generates high accuracy score and low false positive rate is preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
